{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41e97f58-d6ea-49ba-9d00-9a3fed307c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 19:40:23.530162: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-13 19:40:23.623592: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-13 19:40:23.623708: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-13 19:40:23.623809: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-13 19:40:23.645989: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-13 19:40:25.493460: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff814a1-2970-449f-9c4e-260b7a6447e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google-t5/t5-base and revision 686f1db (https://huggingface.co/google-t5/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8796d8583bc462480e7c965aeec531f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70346f6368e7458c8531d306aa9f6eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb27f7f13c95482b85b9b5a941bdf22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3807a2c39b64693b436713a3f0a53d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5_fast.py:171: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on google-t5/t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(\"translation_en_to_fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2fc3ca4-ac64-47ba-9df1-86d88594dcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = translator(\"I am Jack.  I am learning french\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a09cd18-41e6-456b-90f2-6d1dd4d1b8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': \"Je suis Jack et j'apprends le français\"}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3132826-fd31-48a8-94b2-f6604c41457d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Je suis Jack et j'apprends le français\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr[0]['translation_text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05c4e968-9cf3-428a-b15b-51911a1ba7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the general idea behind unit testing\n",
      "is that we want to assert that\n",
      "something is true.\n",
      "So we are making sure\n",
      "that a certain condition is met.\n",
      "If it is, then we pass our test\n",
      "and we can move on to the next one.\n",
      "If it is not,\n",
      "then we make changes to our software\n",
      "and we continue changing it all the way\n",
      "until we are able to pass the test.\n",
      "But what exactly are we testing?\n",
      "Which brings me to my awesome testing\n",
      "checklist that you can find on my GitHub.\n",
      "I will explain and demonstrate\n",
      "most of the checklist items, so please\n",
      "feel free to use the time stamps to skip\n",
      "anything you already know.\n",
      "Now the first thing we test\n",
      "is the existence of elements.\n",
      "Is it there or is it not?\n",
      "Or alternatively,\n",
      "can I access this element when I need it?\n",
      "So at this point,\n",
      "we don't really care about the content.\n",
      "We only care\n",
      "if our classes, functions, assets,\n",
      "or other software\n",
      "elements are manifesting.\n",
      "So let's see an example for this.\n",
      "We will rename our test to test underscore\n",
      "app exists.\n",
      "And how do we check if something exists?\n",
      "We simply check if it is not none.\n",
      "Where none represents the absence of data\n",
      "or simply nothing.\n",
      "For this\n",
      "we will use a statement called self.\n",
      "Dot assert is not known in camel case.\n",
      "And as you may guess,\n",
      "this statement will receive\n",
      "our app is an argument,\n",
      "but how exactly can we target our app?\n",
      "So let's go back to our my app\n",
      "dot p file and let's navigate below.\n",
      "Let's look for the command\n",
      "that runs our application,\n",
      "which is something that we usually find\n",
      "at the very, very end of the file\n",
      "wrapped in an\n",
      "if name equals main statement.\n",
      "Now in our case, we run the app\n",
      "with Pythagoras and Dot Run.\n",
      "So let's quickly copy Pythagorean\n",
      "because we don't want to type it again\n",
      "and back in our test file.\n",
      "It will create a local variable inside\n",
      "our first test called app\n",
      "and we will assign it to my app\n",
      "Dot Pythagoras.\n",
      "Remember, because we are importing my app,\n",
      "we need to specify my app\n",
      "in front of the Pythagorean Plus.\n",
      "Now let's quickly print\n",
      "it right below\n",
      "just because I want to have a quick look.\n",
      "And lastly,\n",
      "we'll pass it into our assertion.\n",
      "So there you go.\n",
      "App Awesome.\n",
      "Now let's save it.\n",
      "Let's quickly run it with Python.\n",
      "Just underscore my app dot p y and lovely.\n",
      "We ran one test and we passed it.\n",
      "Given this lovely. Okay.\n",
      "We've also printed our app object, which\n",
      "doesn't tell us much,\n",
      "but this is how it looks like.\n",
      "Great.\n",
      "We now know how to test\n",
      "for the existence of classes.\n",
      "We can now move on with some other\n",
      "checklist elements.\n",
      "For example, UI elements also known\n",
      "as widgets.\n"
     ]
    }
   ],
   "source": [
    "import pysrt\n",
    "subs = pysrt.open(\"captions_english.srt\")\n",
    "for i in subs:\n",
    "    print (i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b078587-a1dc-430e-bc15-71fe6f590e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in subs:\n",
    "    fr_text = translator(i.text)[0]['translation_text']\n",
    "    i.text = fr_text\n",
    "\n",
    "subs.save(\"captions_french.srt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
